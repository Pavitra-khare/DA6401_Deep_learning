{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavitra-khare/DA6401_Deep_learning/blob/main/DA6401_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "381edf3f-a1eb-40d7-bb12-399a73d447bf",
      "metadata": {
        "id": "381edf3f-a1eb-40d7-bb12-399a73d447bf",
        "outputId": "1cc4c670-2619-4bff-b49f-2f3f405eb806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras\n",
            "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting absl-py (from keras)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras) (13.3.5)\n",
            "Collecting namex (from keras)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.12/site-packages (from keras) (3.11.0)\n",
            "Collecting optree (from keras)\n",
            "  Downloading optree-0.14.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m134.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting ml-dtypes (from keras)\n",
            "  Downloading ml_dtypes-0.5.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from keras) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optree->keras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
            "Downloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m258.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m146.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp312-cp312-macosx_10_9_universal2.whl (670 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.4/670.4 kB\u001b[0m \u001b[31m200.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.14.0-cp312-cp312-macosx_11_0_arm64.whl (335 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.8/335.8 kB\u001b[0m \u001b[31m178.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: namex, optree, ml-dtypes, absl-py, keras\n",
            "Successfully installed absl-py-2.1.0 keras-3.8.0 ml-dtypes-0.5.1 namex-0.0.8 optree-0.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f307325a-7e48-4442-800f-73e35f075681",
      "metadata": {
        "id": "f307325a-7e48-4442-800f-73e35f075681",
        "outputId": "ec4dee08-8a20-4bd5-ef6c-bcca4f308169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.18.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow)\n",
            "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
            "  Downloading grpcio-1.70.0-cp312-cp312-macosx_10_14_universal2.whl.metadata (3.9 kB)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
            "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (20 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
            "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.4.1)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Downloading tensorflow-2.18.0-cp312-cp312-macosx_12_0_arm64.whl (239.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 MB\u001b[0m \u001b[31m167.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:39\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m225.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.70.0-cp312-cp312-macosx_10_14_universal2.whl (11.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m159.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m202.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl (405 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m121.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m186.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m164.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
            "Installing collected packages: libclang, flatbuffers, termcolor, tensorboard-data-server, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, tensorboard, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml_dtypes 0.5.1\n",
            "    Uninstalling ml_dtypes-0.5.1:\n",
            "      Successfully uninstalled ml_dtypes-0.5.1\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 libclang-18.1.1 ml-dtypes-0.4.1 opt-einsum-3.4.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 termcolor-2.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6YrhAjbxPeM",
        "outputId": "537b6073-0f13-4d22-8673-68e7b27bda57"
      },
      "id": "x6YrhAjbxPeM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlQ_3RxXxVV0",
        "outputId": "83d85d0e-f803-4d82-c99a-799af9fad15f"
      },
      "id": "ZlQ_3RxXxVV0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m3628-pavitrakhare\u001b[0m (\u001b[33m3628-pavitrakhare-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7QCrzQsgxedB"
      },
      "id": "7QCrzQsgxedB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "# Initialize Weights & Biases (W&B) for experiment tracking\n",
        "wandb.init(project=\"DA6401-assignment_1\", name=\"Question-1\")\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Define class names for Fashion MNIST\n",
        "class_names = [\n",
        "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
        "]\n",
        "\n",
        "# Select one sample image for each class\n",
        "selected_images = []\n",
        "selected_labels = set()\n",
        "\n",
        "for i, label in enumerate(train_labels):\n",
        "    if label not in selected_labels:\n",
        "        selected_images.append((train_images[i], class_names[label]))\n",
        "        selected_labels.add(label)\n",
        "    if len(selected_images) == 10:\n",
        "        break\n",
        "\n",
        "# Plot sample images\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "fig.suptitle(\"Sample Images from Fashion MNIST\", fontsize=16)\n",
        "\n",
        "for ax, (image, label) in zip(axes.flatten(), selected_images):\n",
        "    ax.imshow(image, cmap='gray')\n",
        "    ax.set_title(label)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Log the figure to W&B\n",
        "wandb.log({\"Sample MNIST Images\": fig})\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "ZBch0x4-TT34",
        "outputId": "3b0f038a-a02b-4076-b82e-cb6a271f51fa"
      },
      "id": "ZBch0x4-TT34",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-763a6adbab37>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Initialize Weights & Biases (W&B) for experiment tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DA6401-assignment_1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Question-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load the Fashion MNIST dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1469\u001b[0m             \u001b[0minit_telemetry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard_sync\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, settings, config)\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m                 result = wait_with_progress(\n\u001b[0m\u001b[1;32m    947\u001b[0m                     \u001b[0mrun_init_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/mailbox/wait_with_progress.py\u001b[0m in \u001b[0;36mwait_with_progress\u001b[0;34m(handle, timeout, progress_after, display_progress)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mEquivalent\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpassing\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mwait_all_with_progress\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[0;32m---> 23\u001b[0;31m     return wait_all_with_progress(\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/mailbox/wait_with_progress.py\u001b[0m in \u001b[0;36mwait_all_with_progress\u001b[0;34m(handle_list, timeout, progress_after, display_progress)\u001b[0m\n\u001b[1;32m     84\u001b[0m             )\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0masyncio_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_loop_with_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/asyncio_compat.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c21950ab-3ad0-400f-b317-46581baeb552",
      "metadata": {
        "id": "c21950ab-3ad0-400f-b317-46581baeb552"
      },
      "source": [
        "# QUESTION 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def activation_sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "VLPDTnHE71Xl"
      },
      "id": "VLPDTnHE71Xl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    exp_values = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_values / np.sum(exp_values, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "9Mhlu5SyC78G"
      },
      "id": "9Mhlu5SyC78G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_hidden_layers(no_of_hidden_layers, neurons_per_layer):\n",
        "    return [neurons_per_layer] * no_of_hidden_layers"
      ],
      "metadata": {
        "id": "JQpTvkbKFqLg"
      },
      "id": "JQpTvkbKFqLg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n"
      ],
      "metadata": {
        "id": "gNSjMzdIYCd5"
      },
      "id": "gNSjMzdIYCd5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(input_data, model_params, layer_sizes):\n",
        "    layer_outputs = {\"A0\": input_data}\n",
        "    num_layers = len(layer_sizes) + 1\n",
        "\n",
        "    for layer_idx in range(1, num_layers):\n",
        "        linear_combination = np.dot(layer_outputs[f\"A{layer_idx-1}\"], model_params[f\"W{layer_idx}\"]) + model_params[f\"b{layer_idx}\"]\n",
        "        layer_outputs[f\"A{layer_idx}\"] = sigmoid(linear_combination)\n",
        "\n",
        "    final_combination = np.dot(layer_outputs[f\"A{num_layers-1}\"], model_params[f\"W{num_layers}\"]) + model_params[f\"b{num_layers}\"]\n",
        "    layer_outputs[f\"A{num_layers}\"] = softmax(final_combination)\n",
        "\n",
        "    return layer_outputs\n"
      ],
      "metadata": {
        "id": "9wMn710l8Gtn"
      },
      "id": "9wMn710l8Gtn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QUESTION 3\n"
      ],
      "metadata": {
        "id": "J7zJCBJG9oTd"
      },
      "id": "J7zJCBJG9oTd"
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_model_params(input_size, hidden_units, output_size):\n",
        "    np.random.seed(42)\n",
        "    layer_structure = [input_size] + hidden_units + [output_size]\n",
        "    model_params = {}\n",
        "\n",
        "    for idx in range(1, len(layer_structure)):\n",
        "        model_params[f'W{idx}'] = np.random.randn(layer_structure[idx-1], layer_structure[idx]) * 0.01\n",
        "        model_params[f'b{idx}'] = np.zeros((1, layer_structure[idx]))\n",
        "\n",
        "    return model_params\n"
      ],
      "metadata": {
        "id": "2rGv7e-lVg5I"
      },
      "id": "2rGv7e-lVg5I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_error(actual, predicted):\n",
        "    samples = actual.shape[0]\n",
        "    return -np.sum(actual * np.log(predicted + 1e-8)) / samples"
      ],
      "metadata": {
        "id": "tKkR5DovVhjT"
      },
      "id": "tKkR5DovVhjT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def activation_sigmoid_derivative(x):\n",
        "\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "4zZW9jXLwEij"
      },
      "id": "4zZW9jXLwEij",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagate(X, y_true, parameters, hidden_layers, optimizer, learning_rate, beta=0.9, beta2=0.999, epsilon=1e-8):\n",
        "    activations = forward_pass(X, parameters, hidden_layers)\n",
        "    m = X.shape[0]\n",
        "    grads = {}\n",
        "    v = {key: np.zeros_like(value) for key, value in parameters.items()}\n",
        "    s = {key: np.zeros_like(value) for key, value in parameters.items()}\n",
        "    L = len(hidden_layers) + 1\n",
        "\n",
        "\n",
        "    dZ = activations[f'A{L}'] - y_true\n",
        "\n",
        "    for i in reversed(range(1, L + 1)):\n",
        "        grads[f'dW{i}'] = np.dot(activations[f'A{i-1}'].T, dZ) / m\n",
        "        grads[f'db{i}'] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "        if i > 1:\n",
        "            dZ = np.dot(dZ, parameters[f'W{i}'].T) * activations[f'A{i-1}'] * (1 - activations[f'A{i-1}'])\n",
        "\n",
        "\n",
        "    for key in parameters:\n",
        "        grad_key = f'd{key}'\n",
        "        if optimizer == \"sgd\":\n",
        "            parameters[key] -= learning_rate * grads.get(grad_key, 0)\n",
        "        elif optimizer == \"momentum\":\n",
        "            v[key] = beta * v[key] + (1 - beta) * grads.get(grad_key, 0)\n",
        "            parameters[key] -= learning_rate * v[key]\n",
        "        elif optimizer == \"nesterov\":\n",
        "            v[key] = beta * v[key] + (1 - beta) * grads.get(grad_key, 0)\n",
        "            parameters[key] -= learning_rate * beta * v[key]\n",
        "        elif optimizer == \"rmsprop\":\n",
        "            s[key] = beta * s[key] + (1 - beta) * np.square(grads.get(grad_key, 0))\n",
        "            parameters[key] -= learning_rate * grads.get(grad_key, 0) / (np.sqrt(s[key]) + epsilon)\n",
        "        elif optimizer == \"adam\":\n",
        "            v[key] = beta * v[key] + (1 - beta) * grads.get(grad_key, 0)\n",
        "            s[key] = beta2 * s[key] + (1 - beta2) * np.square(grads.get(grad_key, 0))\n",
        "            parameters[key] -= learning_rate * v[key] / (np.sqrt(s[key]) + epsilon)\n",
        "        elif optimizer == \"nadam\":\n",
        "            v[key] = beta * v[key] + (1 - beta) * grads.get(grad_key, 0)\n",
        "            s[key] = beta2 * s[key] + (1 - beta2) * np.square(grads.get(grad_key, 0))\n",
        "            parameters[key] -= learning_rate * (beta * v[key] + (1 - beta) * grads.get(grad_key, 0)) / (np.sqrt(s[key]) + epsilon)\n",
        "\n",
        "    return parameters\n"
      ],
      "metadata": {
        "id": "KtAYLKDq3tRf"
      },
      "id": "KtAYLKDq3tRf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = images[:5].reshape(5, -1)  # Flatten images\n",
        "y_train = np.eye(10)[labels_index[:5]]  # One-hot encode labels\n",
        "\n",
        "parameters = setup_model_params(X_train.shape[1], [128, 64], 10)\n",
        "\n",
        "for epoch in range(10):\n",
        "    parameters = backpropagate(X_train, y_train, parameters, [128, 64], optimizer=\"adam\", learning_rate=0.01)\n",
        "    predictions = forward_pass(X_train, parameters, [128, 64])[f\"A{len([128, 64]) + 1}\"]  # Ensure correct indexing\n",
        "    loss = calculate_error(y_train, predictions)\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyCzuSmy9tLS",
        "outputId": "ca0bbe7a-5a36-4db5-ac2f-c64b08ac587b"
      },
      "id": "pyCzuSmy9tLS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.3602\n",
            "Epoch 2, Loss: 1.2778\n",
            "Epoch 3, Loss: 1.1213\n",
            "Epoch 4, Loss: 1.2231\n",
            "Epoch 5, Loss: 1.0618\n",
            "Epoch 6, Loss: 1.0684\n",
            "Epoch 7, Loss: 0.9595\n",
            "Epoch 8, Loss: 0.7840\n",
            "Epoch 9, Loss: 0.8232\n",
            "Epoch 10, Loss: 0.6037\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}